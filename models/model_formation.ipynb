{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the datasets\n",
    "patients_df = pd.read_csv('../data/patients_data (1).csv')\n",
    "doctors_df = pd.read_csv('../data/doctors-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_align_features(patients_df, doctors_df):\n",
    "    # Combine languages for doctors and handle NaNs\n",
    "    doctors_df['language_combined'] = doctors_df['language_1'].fillna('') + ',' + doctors_df['language_2'].fillna('')\n",
    "    \n",
    "    # Initialize OneHotEncoder\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Encode 'sex' and 'location' using LabelEncoder for simplicity\n",
    "    for column in ['sex', 'location']:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([patients_df[column].fillna('Unknown'), doctors_df[column].fillna('Unknown')])\n",
    "        le.fit(combined)\n",
    "        patients_df[column + '_encoded'] = le.transform(patients_df[column].fillna('Unknown'))\n",
    "        doctors_df[column + '_encoded'] = le.transform(doctors_df[column].fillna('Unknown'))\n",
    "    \n",
    "    # Convert 'budget_max' and 'cost_max' to numeric, ensuring columns exist and are not null before attempting string operations\n",
    "    if 'budget_max' in patients_df.columns and patients_df['budget_max'].dtype == object:\n",
    "        patients_df['budget_max'] = pd.to_numeric(patients_df['budget_max'].str.replace('[\\$,]', '', regex=True), errors='coerce').fillna(0)\n",
    "    \n",
    "    if 'cost_max' in doctors_df.columns and doctors_df['cost_max'].dtype == object:\n",
    "        doctors_df['cost_max'] = pd.to_numeric(doctors_df['cost_max'].str.replace('[\\$,]', '', regex=True), errors='coerce').fillna(0)\n",
    "    \n",
    "    # Handle insurance by creating a simplified matching column for each patient's insurance in the doctors DataFrame\n",
    "    unique_insurances = patients_df['Insurance_plan'].dropna().unique()\n",
    "    for insurance in unique_insurances:\n",
    "        insurance_column = 'accepts_' + insurance.replace(' ', '_').replace('/', '_')\n",
    "        doctors_df[insurance_column] = doctors_df.apply(lambda x: 1 if insurance in x.values else 0, axis=1)\n",
    "    \n",
    "    return patients_df, doctors_df\n",
    "\n",
    "patients_df_aligned, doctors_df_aligned = preprocess_align_features(patients_df, doctors_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>location</th>\n",
       "      <th>language_preference</th>\n",
       "      <th>Insurance_plan</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>doctor's_gender_preference</th>\n",
       "      <th>location_radious_prefernce</th>\n",
       "      <th>consultation_location</th>\n",
       "      <th>problem</th>\n",
       "      <th>budget_max</th>\n",
       "      <th>communication_preference</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>location_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Kirby</td>\n",
       "      <td>2/3/2003</td>\n",
       "      <td>Brookline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humana</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>30 miles</td>\n",
       "      <td>virtual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>less conversational</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Smith</td>\n",
       "      <td>8/19/1941</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MassHealth</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>30 miles</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>fever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p3</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Reynolds</td>\n",
       "      <td>12/1/2004</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>Humana</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>50 miles</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>headache</td>\n",
       "      <td>500.0</td>\n",
       "      <td>less conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Payne</td>\n",
       "      <td>5/28/1951</td>\n",
       "      <td>Roxbury</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Blue Cross Blue Shield</td>\n",
       "      <td>F</td>\n",
       "      <td>Latino</td>\n",
       "      <td>F</td>\n",
       "      <td>30 miles</td>\n",
       "      <td>virtual</td>\n",
       "      <td>cough</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p5</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>10/18/2005</td>\n",
       "      <td>Charlestown</td>\n",
       "      <td>Russian</td>\n",
       "      <td>MassHealth</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>In-person</td>\n",
       "      <td>fatigue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>p96</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>6/25/1989</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>Cigna</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>In-person</td>\n",
       "      <td>back pain</td>\n",
       "      <td>100.0</td>\n",
       "      <td>less conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>p97</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Flores</td>\n",
       "      <td>5/10/1989</td>\n",
       "      <td>South End</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>MassHealth</td>\n",
       "      <td>Other</td>\n",
       "      <td>Arab</td>\n",
       "      <td>F</td>\n",
       "      <td>50 miles</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more conversational</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>p98</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Phillips</td>\n",
       "      <td>12/25/1976</td>\n",
       "      <td>Charlestown</td>\n",
       "      <td>French</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Other</td>\n",
       "      <td>Arab</td>\n",
       "      <td>M</td>\n",
       "      <td>50 miles</td>\n",
       "      <td>In-person</td>\n",
       "      <td>back pain</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>p99</td>\n",
       "      <td>Brandi</td>\n",
       "      <td>Herrera</td>\n",
       "      <td>5/28/1959</td>\n",
       "      <td>Roxbury</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>Blue Cross Blue Shield</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>In-person</td>\n",
       "      <td>skin rash</td>\n",
       "      <td>100.0</td>\n",
       "      <td>more conversational</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>p100</td>\n",
       "      <td>Brent</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>4/29/1948</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>English</td>\n",
       "      <td>MassHealth</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>F</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>more conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id first_name last_name date_of_birth     location  \\\n",
       "0          p1       Mark     Kirby      2/3/2003    Brookline   \n",
       "1          p2     Lauren     Smith     8/19/1941     Back Bay   \n",
       "2          p3       Eric  Reynolds     12/1/2004    Cambridge   \n",
       "3          p4       Mark     Payne     5/28/1951      Roxbury   \n",
       "4          p5      Bobby  Martinez    10/18/2005  Charlestown   \n",
       "..        ...        ...       ...           ...          ...   \n",
       "95        p96  Elizabeth  Martinez     6/25/1989     Brighton   \n",
       "96        p97     Daniel    Flores     5/10/1989    South End   \n",
       "97        p98  Katherine  Phillips    12/25/1976  Charlestown   \n",
       "98        p99     Brandi   Herrera     5/28/1959      Roxbury   \n",
       "99       p100      Brent  Robinson     4/29/1948     Back Bay   \n",
       "\n",
       "   language_preference          Insurance_plan    sex ethnicity  \\\n",
       "0                  NaN                  Humana      F  Hispanic   \n",
       "1                  NaN              MassHealth      M       NaN   \n",
       "2             Mandarin                  Humana      M  Hispanic   \n",
       "3              Russian  Blue Cross Blue Shield      F    Latino   \n",
       "4              Russian              MassHealth      M     White   \n",
       "..                 ...                     ...    ...       ...   \n",
       "95            Mandarin                   Cigna      M     White   \n",
       "96              Arabic              MassHealth  Other      Arab   \n",
       "97              French                  Humana  Other      Arab   \n",
       "98            Mandarin  Blue Cross Blue Shield      F  Hispanic   \n",
       "99             English              MassHealth      M     Black   \n",
       "\n",
       "   doctor's_gender_preference location_radious_prefernce  \\\n",
       "0               No Preference                   30 miles   \n",
       "1                           F                   30 miles   \n",
       "2               No Preference                   50 miles   \n",
       "3                           F                   30 miles   \n",
       "4                           M              No Preference   \n",
       "..                        ...                        ...   \n",
       "95                          M              No Preference   \n",
       "96                          F                   50 miles   \n",
       "97                          M                   50 miles   \n",
       "98                          M              No Preference   \n",
       "99                          F              No Preference   \n",
       "\n",
       "   consultation_location    problem  budget_max communication_preference  \\\n",
       "0                virtual        NaN       300.0      less conversational   \n",
       "1          No Preference      fever         NaN      more conversational   \n",
       "2          No Preference   headache       500.0      less conversational   \n",
       "3                virtual      cough       200.0                      NaN   \n",
       "4              In-person    fatigue         NaN      more conversational   \n",
       "..                   ...        ...         ...                      ...   \n",
       "95             In-person  back pain       100.0      less conversational   \n",
       "96         No Preference        NaN         NaN      more conversational   \n",
       "97             In-person  back pain       100.0                      NaN   \n",
       "98             In-person  skin rash       100.0      more conversational   \n",
       "99         No Preference        NaN       200.0      more conversational   \n",
       "\n",
       "    sex_encoded  location_encoded  \n",
       "0             0                 3  \n",
       "1             1                 0  \n",
       "2             1                 4  \n",
       "3             0                 8  \n",
       "4             1                 5  \n",
       "..          ...               ...  \n",
       "95            1                 2  \n",
       "96            2                10  \n",
       "97            2                 5  \n",
       "98            0                 8  \n",
       "99            1                 0  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_df_aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>location</th>\n",
       "      <th>language_1</th>\n",
       "      <th>language_2</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>availability</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>language_combined</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>location_encoded</th>\n",
       "      <th>accepts_Humana</th>\n",
       "      <th>accepts_MassHealth</th>\n",
       "      <th>accepts_Blue_Cross_Blue_Shield</th>\n",
       "      <th>accepts_Aetna</th>\n",
       "      <th>accepts_Cigna</th>\n",
       "      <th>accepts_UnitedHealthcare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>Crystal</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>9/4/1983</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>English</td>\n",
       "      <td>Russian</td>\n",
       "      <td>F</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Russian</td>\n",
       "      <td>English,Russian</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>Gray</td>\n",
       "      <td>1/7/1975</td>\n",
       "      <td>South End</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>English,Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Short</td>\n",
       "      <td>1/15/1987</td>\n",
       "      <td>West End</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>Other</td>\n",
       "      <td>Asian</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French</td>\n",
       "      <td>English,French</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>Roy</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>10/17/1966</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French</td>\n",
       "      <td>English,French</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Watson</td>\n",
       "      <td>2/25/1976</td>\n",
       "      <td>South End</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French</td>\n",
       "      <td>English,French</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d6</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>Smith</td>\n",
       "      <td>1/13/1973</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>F</td>\n",
       "      <td>Asian</td>\n",
       "      <td>morning</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>English,Spanish</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d7</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Miller</td>\n",
       "      <td>3/31/1973</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French</td>\n",
       "      <td>English,French</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d8</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Woodard</td>\n",
       "      <td>10/22/1986</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>English</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>English,Mandarin</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d9</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>9/11/1990</td>\n",
       "      <td>Roxbury</td>\n",
       "      <td>English</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>morning</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Portuguese</td>\n",
       "      <td>English,Portuguese</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d10</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Knox</td>\n",
       "      <td>5/26/1969</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>English</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>F</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Portuguese</td>\n",
       "      <td>English,Portuguese</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d11</td>\n",
       "      <td>Roy</td>\n",
       "      <td>Morris</td>\n",
       "      <td>5/14/1966</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French</td>\n",
       "      <td>English,French</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d12</td>\n",
       "      <td>Katelyn</td>\n",
       "      <td>Bradshaw</td>\n",
       "      <td>8/29/1968</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Other</td>\n",
       "      <td>White</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>English,Spanish</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d13</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>Williams</td>\n",
       "      <td>2/11/1969</td>\n",
       "      <td>Dorchester</td>\n",
       "      <td>English</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>English,Mandarin</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d14</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Shah</td>\n",
       "      <td>10/1/1975</td>\n",
       "      <td>South End</td>\n",
       "      <td>English</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>M</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>English,Mandarin</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d15</td>\n",
       "      <td>Heidi</td>\n",
       "      <td>Cooper</td>\n",
       "      <td>12/4/1979</td>\n",
       "      <td>Back Bay</td>\n",
       "      <td>English</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>M</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>English,Mandarin</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d16</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Kirk</td>\n",
       "      <td>2/5/1985</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>morning</td>\n",
       "      <td>...</td>\n",
       "      <td>English,</td>\n",
       "      <td>English,</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d17</td>\n",
       "      <td>Jamie</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>1/13/1986</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Other</td>\n",
       "      <td>Black</td>\n",
       "      <td>evening</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>English,Spanish</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>d18</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>6/13/1966</td>\n",
       "      <td>Charlestown</td>\n",
       "      <td>English</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>English,Mandarin</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d19</td>\n",
       "      <td>Shannon</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>12/25/1974</td>\n",
       "      <td>Charlestown</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>...</td>\n",
       "      <td>English,</td>\n",
       "      <td>English,</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d20</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Best</td>\n",
       "      <td>4/3/1992</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morning</td>\n",
       "      <td>...</td>\n",
       "      <td>English, French</td>\n",
       "      <td>English,French</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doctor_id   first_name   last_name date_of_birth     location language_1  \\\n",
       "0         d1      Crystal     Anthony      9/4/1983   Dorchester    English   \n",
       "1         d2       Johnny        Gray      1/7/1975    South End    English   \n",
       "2         d3         Mark       Short     1/15/1987     West End    English   \n",
       "3         d4          Roy     Burgess    10/17/1966   Dorchester    English   \n",
       "4         d5      Richard      Watson     2/25/1976    South End    English   \n",
       "5         d6        Jacob       Smith     1/13/1973   Dorchester    English   \n",
       "6         d7          Amy      Miller     3/31/1973       Fenway    English   \n",
       "7         d8  Christopher     Woodard    10/22/1986       Fenway    English   \n",
       "8         d9        Emily  Williamson     9/11/1990      Roxbury    English   \n",
       "9        d10      Jessica        Knox     5/26/1969       Fenway    English   \n",
       "10       d11          Roy      Morris     5/14/1966     Back Bay    English   \n",
       "11       d12      Katelyn    Bradshaw     8/29/1968   Dorchester    English   \n",
       "12       d13      Brandon    Williams     2/11/1969   Dorchester    English   \n",
       "13       d14        Linda        Shah     10/1/1975    South End    English   \n",
       "14       d15        Heidi      Cooper     12/4/1979     Back Bay    English   \n",
       "15       d16        Brian        Kirk      2/5/1985     Brighton    English   \n",
       "16       d17        Jamie      Hudson     1/13/1986     Brighton    English   \n",
       "17       d18       Nicole     Johnson     6/13/1966  Charlestown    English   \n",
       "18       d19      Shannon     Estrada    12/25/1974  Charlestown    English   \n",
       "19       d20       Robert        Best      4/3/1992     Brighton    English   \n",
       "\n",
       "    language_2    sex       ethnicity availability  ...             language  \\\n",
       "0      Russian      F  Middle Eastern      evening  ...     English, Russian   \n",
       "1      Spanish      M             NaN      evening  ...     English, Spanish   \n",
       "2       French  Other           Asian    afternoon  ...      English, French   \n",
       "3       French      M        Hispanic      evening  ...      English, French   \n",
       "4       French  Other        Hispanic    afternoon  ...      English, French   \n",
       "5      Spanish      F           Asian      morning  ...     English, Spanish   \n",
       "6       French      F           White      evening  ...      English, French   \n",
       "7     Mandarin      M           Black    afternoon  ...    English, Mandarin   \n",
       "8   Portuguese      M           Black      morning  ...  English, Portuguese   \n",
       "9   Portuguese      F  Middle Eastern    afternoon  ...  English, Portuguese   \n",
       "10      French      M           White      evening  ...      English, French   \n",
       "11     Spanish  Other           White      evening  ...     English, Spanish   \n",
       "12    Mandarin  Other             NaN    afternoon  ...    English, Mandarin   \n",
       "13    Mandarin      M  Middle Eastern      evening  ...    English, Mandarin   \n",
       "14    Mandarin      M  Middle Eastern      evening  ...    English, Mandarin   \n",
       "15         NaN      F  Middle Eastern      morning  ...            English,    \n",
       "16     Spanish  Other           Black      evening  ...     English, Spanish   \n",
       "17    Mandarin      F           White    afternoon  ...    English, Mandarin   \n",
       "18         NaN      M        Hispanic    afternoon  ...            English,    \n",
       "19      French  Other             NaN      morning  ...      English, French   \n",
       "\n",
       "     language_combined sex_encoded location_encoded accepts_Humana  \\\n",
       "0      English,Russian           0                6              0   \n",
       "1      English,Spanish           1               10              0   \n",
       "2       English,French           2               11              0   \n",
       "3       English,French           1                6              0   \n",
       "4       English,French           2               10              0   \n",
       "5      English,Spanish           0                6              0   \n",
       "6       English,French           0                7              0   \n",
       "7     English,Mandarin           1                7              0   \n",
       "8   English,Portuguese           1                8              0   \n",
       "9   English,Portuguese           0                7              0   \n",
       "10      English,French           1                0              0   \n",
       "11     English,Spanish           2                6              0   \n",
       "12    English,Mandarin           2                6              0   \n",
       "13    English,Mandarin           1               10              0   \n",
       "14    English,Mandarin           1                0              0   \n",
       "15            English,           0                2              0   \n",
       "16     English,Spanish           2                2              0   \n",
       "17    English,Mandarin           0                5              0   \n",
       "18            English,           1                5              0   \n",
       "19      English,French           2                2              0   \n",
       "\n",
       "   accepts_MassHealth accepts_Blue_Cross_Blue_Shield accepts_Aetna  \\\n",
       "0                   0                              0             0   \n",
       "1                   0                              0             0   \n",
       "2                   0                              0             0   \n",
       "3                   0                              0             0   \n",
       "4                   0                              0             0   \n",
       "5                   0                              0             0   \n",
       "6                   0                              0             0   \n",
       "7                   0                              0             0   \n",
       "8                   0                              0             0   \n",
       "9                   0                              0             0   \n",
       "10                  0                              0             0   \n",
       "11                  0                              0             0   \n",
       "12                  0                              0             0   \n",
       "13                  0                              0             0   \n",
       "14                  0                              0             0   \n",
       "15                  0                              0             0   \n",
       "16                  0                              0             0   \n",
       "17                  0                              0             0   \n",
       "18                  0                              0             0   \n",
       "19                  0                              0             0   \n",
       "\n",
       "   accepts_Cigna accepts_UnitedHealthcare  \n",
       "0              0                        0  \n",
       "1              0                        0  \n",
       "2              0                        0  \n",
       "3              0                        0  \n",
       "4              0                        0  \n",
       "5              0                        0  \n",
       "6              0                        0  \n",
       "7              0                        0  \n",
       "8              0                        0  \n",
       "9              0                        0  \n",
       "10             0                        0  \n",
       "11             0                        0  \n",
       "12             0                        0  \n",
       "13             0                        0  \n",
       "14             0                        0  \n",
       "15             0                        0  \n",
       "16             0                        0  \n",
       "17             0                        0  \n",
       "18             0                        0  \n",
       "19             0                        0  \n",
       "\n",
       "[20 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctors_df_aligned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df['budget_max_scaled'] = scaler.fit_transform(patients_df[['budget_max']].fillna(0).to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_features = np.hstack([\n",
    "    patients_df[['sex_encoded', 'location_encoded']].to_numpy(),\n",
    "    patients_df[['budget_max_scaled']].to_numpy()  # Now this column exists\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_similarity = cosine_similarity(patient_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_doctors(patient_index, top_n=5):\n",
    "    # Find top N similar patients\n",
    "    similarity_scores = patient_similarity[patient_index]\n",
    "    top_patient_indices = np.argsort(similarity_scores)[-top_n-1:-1][::-1]  # Exclude self\n",
    "\n",
    "    # Aggregate preferences (e.g., average budget) from similar patients\n",
    "    avg_budget = np.mean(patients_df.loc[top_patient_indices, 'budget_max'])\n",
    "    \n",
    "    # Filter doctors based on aggregated preferences and compute similarity\n",
    "    suitable_doctors = doctors_df[doctors_df['cost_max'] <= avg_budget]\n",
    "    \n",
    "    # Create feature vectors for suitable doctors\n",
    "    doctor_features = suitable_doctors[['sex_encoded', 'location_encoded', 'cost_max_scaled']].to_numpy()\n",
    "    \n",
    "    # Compute cosine similarity between aggregated patient preferences and suitable doctors\n",
    "    doctor_similarity = cosine_similarity([patient_features[patient_index]], doctor_features)\n",
    "    \n",
    "    # Recommend top N doctors based on similarity scores\n",
    "    top_doctor_indices = np.argsort(doctor_similarity[0])[-top_n:][::-1]\n",
    "    return suitable_doctors.iloc[top_doctor_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['cost_max_scaled'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m patient_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Assuming you want recommendations for the first patient\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m recommended_doctors \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_doctors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommended_doctors)\n",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m, in \u001b[0;36mrecommend_doctors\u001b[1;34m(patient_index, top_n)\u001b[0m\n\u001b[0;32m     10\u001b[0m suitable_doctors \u001b[38;5;241m=\u001b[39m doctors_df[doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_max\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m avg_budget]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Create feature vectors for suitable doctors\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m doctor_features \u001b[38;5;241m=\u001b[39m \u001b[43msuitable_doctors\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msex_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcost_max_scaled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity between aggregated patient preferences and suitable doctors\u001b[39;00m\n\u001b[0;32m     16\u001b[0m doctor_similarity \u001b[38;5;241m=\u001b[39m cosine_similarity([patient_features[patient_index]], doctor_features)\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['cost_max_scaled'] not in index\""
     ]
    }
   ],
   "source": [
    "patient_index = 0  # Assuming you want recommendations for the first patient\n",
    "recommended_doctors = recommend_doctors(patient_index, top_n=3)\n",
    "print(recommended_doctors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the 'cost_max' column in doctors_df\n",
    "doctors_df['cost_max_scaled'] = scaler.fit_transform(doctors_df[['cost_max']].fillna(0).to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first_name last_name   speciality     location  cost_max\n",
      "15      Brian      Kirk   cardiology     Brighton     300.0\n",
      "9     Jessica      Knox    neurology       Fenway     200.0\n",
      "17     Nicole   Johnson  dermatology  Charlestown     200.0\n"
     ]
    }
   ],
   "source": [
    "def recommend_doctors(patient_index, top_n=5):\n",
    "    # Assuming the similarity computation and aggregation of similar patients' preferences have been done correctly\n",
    "    \n",
    "    # For simplicity, let's consider an average budget based on similar patients (implementation details depend on your similarity computation)\n",
    "    avg_budget = patients_df_aligned.loc[patient_index, 'budget_max_scaled']\n",
    "    \n",
    "    # Filter doctors based on the average budget (scaled) of similar patients\n",
    "    suitable_doctors = doctors_df_aligned[doctors_df_aligned['cost_max_scaled'] <= avg_budget]\n",
    "    \n",
    "    # Assuming we have already computed doctor_features correctly with scaled cost_max\n",
    "    # Compute similarity between the patient preferences and doctors\n",
    "    doctor_similarity = cosine_similarity(patient_features[patient_index].reshape(1, -1), suitable_doctors[['sex_encoded', 'location_encoded', 'cost_max_scaled']].to_numpy())\n",
    "    \n",
    "    # Find top N indices of doctors based on similarity scores\n",
    "    top_doctor_indices = np.argsort(-doctor_similarity[0])[:top_n]\n",
    "    recommended_doctors = suitable_doctors.iloc[top_doctor_indices]\n",
    "    \n",
    "    return recommended_doctors\n",
    "\n",
    "# Now, you can call this function to get recommendations for a given patient index\n",
    "patient_index = 0  # Assuming you want recommendations for the first patient\n",
    "recommended_doctors = recommend_doctors(patient_index, top_n=3)\n",
    "print(recommended_doctors[['first_name', 'last_name', 'speciality', 'location', 'cost_max']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'budget_max' or 'cost_max' still contain NaNs, fill them with 0 or mean value\n",
    "patients_df['budget_max'].fillna(0, inplace=True)\n",
    "doctors_df['cost_max'].fillna(doctors_df['cost_max'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_features = patients_df_aligned[['sex_encoded', 'location_encoded', 'budget_max']].to_numpy()\n",
    "doctor_features = doctors_df_aligned[['sex_encoded', 'location_encoded', 'cost_max']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "patient_features[:, -1] = scaler.fit_transform(patient_features[:, -1].reshape(-1, 1)).flatten()  # Budget\n",
    "doctor_features[:, -1] = scaler.transform(doctor_features[:, -1].reshape(-1, 1)).flatten()  # Cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['budget_max_scaled'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m patient_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([\n\u001b[0;32m      2\u001b[0m     patients_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_numpy(),\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mpatients_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbudget_max_scaled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      4\u001b[0m ])\n\u001b[0;32m      6\u001b[0m patient_similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(patient_features)\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['budget_max_scaled'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "patient_features = np.hstack([\n",
    "    patients_df[['sex_encoded', 'location_encoded']].to_numpy(),\n",
    "    patients_df[['budget_max_scaled']].to_numpy()\n",
    "])\n",
    "\n",
    "patient_similarity = cosine_similarity(patient_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "endswith first arg must be str or a tuple of str, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m     doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_max\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_max\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$,]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m patients_df, doctors_df, patients_language_encoded, doctors_language_encoded, ohe_patients, ohe_doctors\n\u001b[1;32m---> 39\u001b[0m patients_df_aligned, doctors_df_aligned, patients_language_encoded, doctors_language_encoded, ohe_patients, ohe_doctors \u001b[38;5;241m=\u001b[39m \u001b[43malign_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatients_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctors_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Function to compute similarities and recommend doctors will be adjusted to use these aligned and encoded features.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36malign_features\u001b[1;34m(patients_df, doctors_df)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ensure insurance columns align\u001b[39;00m\n\u001b[0;32m     17\u001b[0m insurance_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m doctors_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsurance_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 18\u001b[0m patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpatients_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInsurance_plan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minsurance_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoctors_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Encode other comparable features\u001b[39;00m\n\u001b[0;32m     21\u001b[0m encoder_sex \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit(pd\u001b[38;5;241m.\u001b[39mconcat([patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m], doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36malign_features.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ensure insurance columns align\u001b[39;00m\n\u001b[0;32m     17\u001b[0m insurance_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m doctors_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsurance_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 18\u001b[0m patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsurance_plan\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m insurance_columns \u001b[38;5;28;01mif\u001b[39;00m doctors_df[col]\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mand\u001b[39;00m col\u001b[38;5;241m.\u001b[39mendswith(x)]))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Encode other comparable features\u001b[39;00m\n\u001b[0;32m     21\u001b[0m encoder_sex \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit(pd\u001b[38;5;241m.\u001b[39mconcat([patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m], doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ensure insurance columns align\u001b[39;00m\n\u001b[0;32m     17\u001b[0m insurance_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m doctors_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsurance_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 18\u001b[0m patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsurance_plan\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m insurance_columns \u001b[38;5;28;01mif\u001b[39;00m doctors_df[col]\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Encode other comparable features\u001b[39;00m\n\u001b[0;32m     21\u001b[0m encoder_sex \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit(pd\u001b[38;5;241m.\u001b[39mconcat([patients_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m], doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: endswith first arg must be str or a tuple of str, not float"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Align and preprocess features\n",
    "def align_features(patients_df, doctors_df):\n",
    "\n",
    "    # Correctly handle 'NaN' values for language concatenation\n",
    "    doctors_df['language'] = doctors_df.apply(lambda x: (str(x['language_1']) if not pd.isna(x['language_1']) else '') + ', ' + (str(x['language_2']) if not pd.isna(x['language_2']) else ''), axis=1)\n",
    "    \n",
    "    # One-hot encode 'language_preference' for patients and 'language' for doctors\n",
    "    ohe_patients = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe_doctors = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    patients_language_encoded = ohe_patients.fit_transform(patients_df[['language_preference']].fillna('Unknown')).toarray()\n",
    "    doctors_language_encoded = ohe_doctors.fit_transform(doctors_df[['language']]).toarray()\n",
    "    \n",
    "    # Ensure insurance columns align\n",
    "    insurance_columns = [col for col in doctors_df.columns if col.startswith('Insurance_')]\n",
    "    patients_df['insurance_encoded'] = patients_df['Insurance_plan'].apply(lambda x: ','.join([col for col in insurance_columns if doctors_df[col].any() and col.endswith(x)]))\n",
    "    \n",
    "    # Encode other comparable features\n",
    "    encoder_sex = LabelEncoder().fit(pd.concat([patients_df['sex'], doctors_df['sex']], axis=0))\n",
    "    patients_df['sex_encoded'] = encoder_sex.transform(patients_df['sex'])\n",
    "    doctors_df['sex_encoded'] = encoder_sex.transform(doctors_df['sex'])\n",
    "    \n",
    "    encoder_location = LabelEncoder().fit(pd.concat([patients_df['location'], doctors_df['location']], axis=0))\n",
    "    patients_df['location_encoded'] = encoder_location.transform(patients_df['location'])\n",
    "    doctors_df['location_encoded'] = encoder_location.transform(doctors_df['location'])\n",
    "    \n",
    "    encoder_ethnicity = LabelEncoder().fit(pd.concat([patients_df['ethnicity'].fillna('Unknown'), doctors_df['ethnicity'].fillna('Unknown')], axis=0))\n",
    "    patients_df['ethnicity_encoded'] = encoder_ethnicity.transform(patients_df['ethnicity'].fillna('Unknown'))\n",
    "    doctors_df['ethnicity_encoded'] = encoder_ethnicity.transform(doctors_df['ethnicity'].fillna('Unknown'))\n",
    "    \n",
    "    # Convert budget_max and cost_max to numeric values\n",
    "    patients_df['budget_max'] = pd.to_numeric(patients_df['budget_max'].str.replace('[\\$,]', '', regex=True), errors='coerce')\n",
    "    doctors_df['cost_max'] = pd.to_numeric(doctors_df['cost_max'].str.replace('[\\$,]', '', regex=True), errors='coerce')\n",
    "    \n",
    "    return patients_df, doctors_df, patients_language_encoded, doctors_language_encoded, ohe_patients, ohe_doctors\n",
    "\n",
    "patients_df_aligned, doctors_df_aligned, patients_language_encoded, doctors_language_encoded, ohe_patients, ohe_doctors = align_features(patients_df, doctors_df)\n",
    "\n",
    "# Function to compute similarities and recommend doctors will be adjusted to use these aligned and encoded features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_df['hospital_affiliation'] = doctors_df[['hospital_affiliation1', 'hospital_affiliation2', 'hospital_affiliation3']].apply(lambda x: x.dropna().iloc[0] if x.dropna().any() else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing and encoding features\n",
    "def preprocess_and_encode(df, categorical_features):\n",
    "    le_dict = {}\n",
    "    for feature in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        df[feature] = le.fit_transform(df[feature].fillna('Unknown'))\n",
    "        le_dict[feature] = le\n",
    "    return df, le_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'insurance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'insurance'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m patient_categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage_preference\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnicity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunication_preference\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m doctor_categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124methnicity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeciality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhospital_affiliation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m patients_df, patient_le_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatients_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_categorical_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m doctors_df, doctor_le_dict \u001b[38;5;241m=\u001b[39m preprocess_and_encode(doctors_df, doctor_categorical_features)\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mpreprocess_and_encode\u001b[1;34m(df, categorical_features)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m categorical_features:\n\u001b[0;32m      5\u001b[0m     le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 6\u001b[0m     df[feature] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m     le_dict[feature] \u001b[38;5;241m=\u001b[39m le\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df, le_dict\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'insurance'"
     ]
    }
   ],
   "source": [
    "# Define categorical features for encoding\n",
    "patient_categorical_features = ['language_preference', 'sex', 'ethnicity', 'insurance', 'location', 'problem', 'communication_preference']\n",
    "doctor_categorical_features = ['language_2', 'sex', 'ethnicity', 'speciality', 'hospital_affiliation', 'location', 'insurance']\n",
    "\n",
    "patients_df, patient_le_dict = preprocess_and_encode(patients_df, patient_categorical_features)\n",
    "doctors_df, doctor_le_dict = preprocess_and_encode(doctors_df, doctor_categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'language'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'language'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m     doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_max\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(doctors_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_max\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$,]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m patients_df, doctors_df\n\u001b[1;32m---> 25\u001b[0m patients_df, doctors_df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatients_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctors_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(patients_df, doctors_df)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# Insurance will be binary encoded later\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 9\u001b[0m     combined_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpatients_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m, doctors_df[feature]], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     le\u001b[38;5;241m.\u001b[39mfit(combined_data)\n\u001b[0;32m     11\u001b[0m     patients_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(patients_df[feature]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\GJ\\anaconda3\\envs\\cs640\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'language'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing: Align features and encode categorical variables\n",
    "def preprocess_data(patients_df, doctors_df):\n",
    "    common_features = ['language', 'sex', 'ethnicity', 'location', 'insurance']\n",
    "    \n",
    "    # Handle Insurance as a special case since it's directly comparable but needs encoding\n",
    "    for feature in common_features:\n",
    "        if feature != 'insurance':  # Insurance will be binary encoded later\n",
    "            le = LabelEncoder()\n",
    "            combined_data = pd.concat([patients_df[feature], doctors_df[feature]], ignore_index=True, axis=0).fillna('Unknown')\n",
    "            le.fit(combined_data)\n",
    "            patients_df[f'{feature}_encoded'] = le.transform(patients_df[feature].fillna('Unknown'))\n",
    "            doctors_df[f'{feature}_encoded'] = le.transform(doctors_df[feature].fillna('Unknown'))\n",
    "    \n",
    "    # Binary encode 'insurance' to indicate if a doctor accepts a patient's insurance\n",
    "    patients_insurance = patients_df['insurance'].unique()\n",
    "    for insurance in patients_insurance:\n",
    "        doctors_df[f'accepts_{insurance}'] = doctors_df['insurance'].apply(lambda x: insurance in x)\n",
    "    \n",
    "    # Simplify and encode other features\n",
    "    patients_df['budget_max'] = pd.to_numeric(patients_df['budget_max'].str.replace('[\\$,]', '', regex=True))\n",
    "    doctors_df['cost_max'] = pd.to_numeric(doctors_df['cost_max'].str.replace('[\\$,]', '', regex=True))\n",
    "\n",
    "    return patients_df, doctors_df\n",
    "\n",
    "patients_df, doctors_df = preprocess_data(patients_df, doctors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs640",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
